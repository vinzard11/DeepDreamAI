{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepDreamAI.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "9h5Yp8imjh3F"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import random\n",
        "import os\n",
        "import PIL.Image\n",
        "import cv2\n",
        "from PIL import Image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APf5MHO4qSdD"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwiwAb8Cv67C"
      },
      "source": [
        "base_model = tf.keras.applications.InceptionV3(include_top = False, weights = 'imagenet')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4m4qYgbwgtm"
      },
      "source": [
        "base_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6PfzhDNxak9"
      },
      "source": [
        "img_1 = Image.open('/content/drive/MyDrive/Datasets/Creative AI Dataset/mars.jpg')\n",
        "\n",
        "img_2 = Image.open('/content/drive/MyDrive/Datasets/Creative AI Dataset/eiffel.jpg')\n",
        "\n",
        "image = Image.blend(img_1, img_2, 0.5)\n",
        "\n",
        "image.save(\"img_0.jpg\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yz8xrbaj1aiV"
      },
      "source": [
        "Sample_Image = tf.keras.preprocessing.image.load_img('img_0.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_W_IpORq1lFj"
      },
      "source": [
        "Sample_Image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekkZXqSl108A"
      },
      "source": [
        "np.shape(Sample_Image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjwoKpj2175Q"
      },
      "source": [
        "type(Sample_Image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKwiStlq2Aan"
      },
      "source": [
        "Sample_Image = tf.keras.preprocessing.image.img_to_array(Sample_Image)\n",
        "#Sample_Image = np.array(Sample_Image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enzBJOPw2KHz"
      },
      "source": [
        "type(Sample_Image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBjaaKER2fFp"
      },
      "source": [
        "print(\"Min pixel value = {}, Max pixel value = {}\".format(Sample_Image.min(), Sample_Image.max()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29tVTeKo2twF"
      },
      "source": [
        "Sample_Image = np.array(Sample_Image)/255.0\n",
        "Sample_Image.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUWXtXSy2-3k"
      },
      "source": [
        "print(\"Min pixel value = {}, Max pixel value = {}\".format(Sample_Image.min(), Sample_Image.max()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ccb5Saus3CuT"
      },
      "source": [
        "Sample_Image = tf.expand_dims(Sample_Image, axis = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n10IdWyX3bAy"
      },
      "source": [
        "np.shape(Sample_Image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45mdoS6n3dxF"
      },
      "source": [
        "plt.imshow(np.squeeze(Sample_Image))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iL9igi8p340m"
      },
      "source": [
        "names = ['mixed3', 'mixed5','mixed7']\n",
        "\n",
        "layers = [base_model.get_layer(name).output for name in names]\n",
        "\n",
        "deepdream_model = tf.keras.Model(inputs = base_model.input, outputs = layers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYStq1GI4t2S"
      },
      "source": [
        "deepdream_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8tt2tUL4v9y"
      },
      "source": [
        "activations = deepdream_model(Sample_Image)\n",
        "activations"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlipE_CE47cl"
      },
      "source": [
        "len(activations)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lv0H32Zj4-kP"
      },
      "source": [
        "Sample_Image = tf.squeeze(Sample_Image, axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpZe-V86AjKD"
      },
      "source": [
        "def calc_loss(image,model):\n",
        "  img_batch = tf.expand_dims(image, axis=0)\n",
        "  layer_activations = model(img_batch)\n",
        "  print('ACTIVATION VALUES (LAYER OUTPUT) =\\n', layer_activations)\n",
        "\n",
        "  losses = []\n",
        "  for act in layer_activations:\n",
        "    loss = tf.math.reduce_mean(act)\n",
        "    losses.append(loss)\n",
        "\n",
        "  print('LOSSES (FROM MULTIPLE ACTIVATION LAYERS) = ', losses)\n",
        "  print('LOSSES SHAPE (FROM MULTIPLE ACTIVATION LAYERS) = ', np.shape(losses))\n",
        "  print('SUM OF ALL LOSSES (FROM ALL SELECTED LAYERS)= ', tf.reduce_sum(losses))\n",
        "\n",
        "  return  tf.reduce_sum(losses) # Calculate sum "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGdFtBOsBeGg"
      },
      "source": [
        "loss = calc_loss(tf.Variable(Sample_Image), deepdream_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdhedZnCCLCW"
      },
      "source": [
        "loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGOV6dz9CfK_"
      },
      "source": [
        "@tf.function\n",
        "def deepdream(model, image, step_size):\n",
        "  with tf.GradientTape() as tape:\n",
        "    tape.watch(image)\n",
        "    loss = calc_loss(image, model)\n",
        "\n",
        "  gradients = tape.gradient(loss, image)\n",
        "  print('Gradients = \\n', gradients)  \n",
        "  print('Gradients Shape = \\n', np.shape(gradients))  \n",
        "\n",
        "  gradients /= tf.math.reduce_std(gradients)\n",
        "  image = image + gradients*step_size\n",
        "  image = tf.clip_by_value(image, -1, 1)\n",
        "\n",
        "  return loss, image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cU2AtwoiGuL-"
      },
      "source": [
        "def run_deep_dream_simple(model, image, steps = 100, step_size = 0.01):\n",
        "  image = tf.keras.applications.inception_v3.preprocess_input(image)\n",
        "\n",
        "  for step in range(steps):\n",
        "    loss, image = deepdream(model, image, step_size)\n",
        "\n",
        "    if step % 100 == 0:\n",
        "      plt.figure(figsize=(12,12))\n",
        "      plt.imshow(deprocess(image))\n",
        "      plt.show()\n",
        "      print(\"Step {}, loss {}\".format(step, loss)) \n",
        "\n",
        "  plt.figure(figsize=(12,12))\n",
        "  plt.imshow(deprocess(image))\n",
        "  plt.show()\n",
        "\n",
        "  return deprocess(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8x70u91Ilm7"
      },
      "source": [
        "def deprocess(image):\n",
        "  image = 255*(image + 1.0)/2.0\n",
        "  return tf.cast(image, tf.uint8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_-mUm0SI0l4"
      },
      "source": [
        "Sample_Image = np.array(tf.keras.preprocessing.image.load_img('img_0.jpg'))\n",
        "dream_img = run_deep_dream_simple(model = deepdream_model, image = Sample_Image, steps = 4000, step_size = 0.001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZ1hDRLfJOyq"
      },
      "source": [
        "image = tf.keras.preprocessing.image.load_img(\"img_0.jpg\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJZHz3EqKAAM"
      },
      "source": [
        "dream_name = 'mars_eiffel'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xKPYr5qKAGs"
      },
      "source": [
        "x_size = 910 \n",
        "y_size = 605\n",
        "created_count = 0\n",
        "max_count = 50"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08RDI6l5KAJL"
      },
      "source": [
        "def load_image(filename):\n",
        "    image = PIL.Image.open(filename)\n",
        "    return np.float32(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5XtjSxyKALm"
      },
      "source": [
        "for i in range(0, 50):     \n",
        "    if os.path.isfile('/content/drive/MyDrive/Datasets/Creative AI Dataset/{}/img_{}.jpg'.format(dream_name, i+1)):\n",
        "        print(\"{} present already, continue fetching the frames...\".format(i+1))\n",
        "        \n",
        "    else:\n",
        "        # Call the load image funtion\n",
        "        img_result = load_image(r'/content/drive/MyDrive/Datasets/Creative AI Dataset/{}/img_{}.jpg'.format(dream_name, i))\n",
        "\n",
        "    \n",
        "        # Zoom the image \n",
        "        x_zoom = 2 # this indicates how quick the zoom is \n",
        "        y_zoom = 1\n",
        "        \n",
        "        # Chop off the edges of the image and resize the image back to the original shape. This gives the visual changes of a zoom\n",
        "        img_result = img_result[0+x_zoom : y_size-y_zoom, 0+y_zoom : x_size-x_zoom]\n",
        "        img_result = cv2.resize(img_result, (x_size, y_size))\n",
        "        \n",
        "        # Adjust the RGB value of the image\n",
        "        img_result[:, :, 0] += 2  # red\n",
        "        img_result[:, :, 1] += 2  # green\n",
        "        img_result[:, :, 2] += 2  # blue\n",
        "        \n",
        "        # Deep dream model  \n",
        "        img_result = run_deep_dream_simple(model = deepdream_model, image = img_result, steps = 500, step_size = 0.001)\n",
        "        \n",
        "        # Clip the image, convert the datatype of the array, and then convert to an actual image. \n",
        "        img_result = np.clip(img_result, 0.0, 255.0)\n",
        "        img_result = img_result.astype(np.uint8)\n",
        "        result = PIL.Image.fromarray(img_result, mode='RGB')\n",
        "        \n",
        "        # Save all the frames in the dream location\n",
        "        result.save(r'/content/drive/MyDrive/Datasets/Creative AI Dataset/{}/img_{}.jpg'.format(dream_name, i+1))\n",
        "        \n",
        "        created_count += 1\n",
        "        if created_count > max_count:\n",
        "            break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PbQ7yz7Lfs-"
      },
      "source": [
        "dream_path = '/content/drive/MyDrive/Datasets/Creative AI Dataset/mars_eiffel'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5DYOM4aMTyZ"
      },
      "source": [
        "fourcc = cv2.VideoWriter_fourcc(*'XVID') \n",
        "out = cv2.VideoWriter('deepdreamvideo.avi', fourcc , 5.0, (910, 605))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOdUT7mPMjY1"
      },
      "source": [
        "for i in range(9999999999999):\n",
        "    if os.path.isfile('/content/drive/MyDrive/Datasets/Creative AI Dataset/mars_eiffel/img_{}.jpg'.format(i+1)):\n",
        "        pass\n",
        "    else:\n",
        "        dream_length = i\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8f4CY8nyM636"
      },
      "source": [
        "for i in range(dream_length):\n",
        "    \n",
        "    # Build the frames of cv2.VideoWriter\n",
        "    img_path = os.path.join(dream_path,'img_{}.jpg'.format(i)) # join the dream path\n",
        "    \n",
        "    print(img_path) # print the image path \n",
        "    \n",
        "    frame = cv2.imread(img_path)\n",
        "    out.write(frame)\n",
        "\n",
        "out.release()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vY3d6c9ONiAS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}